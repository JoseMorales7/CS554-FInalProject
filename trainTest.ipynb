{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68587935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vislab-001/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv  # or GraphSAGE, GAT, etc.\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341ebfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b362f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vislab-001/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "sentTransformer = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb').to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822a9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"./publications_clustered_kmeans.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # pubIdToCommunity[int(row[\"node_id\"])] = int(row[\"community_id\"])\n",
    "    sentence = row[\"title\"] + \". \" + str(row[\"abstract\"])\n",
    "    embeddings.append(sentTransformer.encode([sentence]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c563b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings).squeeze(axis=1)\n",
    "np.save(\"./encodedTrainFeatures.npy\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cabd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"./encodedTrainFeatures.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7eb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "allIds = []\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    allIds.append(int(row[\"publication_ID\"]))\n",
    "\n",
    "sortedIds = sorted(allIds)\n",
    "pubIdToId = {id: idx for idx, id in enumerate(sortedIds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc888fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCitations = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # print(doc[\"title\"])\n",
    "    # print(doc[\"abstract\"])\n",
    "    # print(idx)\n",
    "\n",
    "    # print(doc[\"Citations\"])\n",
    "    # print(idx)\n",
    "    if type(row[\"Citations\"]) == int:\n",
    "        continue\n",
    "    citations = row[\"Citations\"].split(\";\")\n",
    "    docId = int(row[\"publication_ID\"])\n",
    "    # print(citations)\n",
    "    for citation in citations:\n",
    "        if citation == \"nan\" or int(citation) not in pubIdToId.keys():\n",
    "            continue\n",
    "        tup = (pubIdToId[docId], pubIdToId[int(citation)])\n",
    "        # print(pubIdToId[docId])\n",
    "        # print(pubIdToId[citation])\n",
    "        # print(tup)\n",
    "        allCitations.append((pubIdToId[docId], pubIdToId[int(citation)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3accfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCommunities = df[\"cluster\"].to_list()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca2210cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(allCommunities, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4687000",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    x=torch.tensor(embeddings),         # [num_nodes, embedding_dim]\n",
    "    edge_index=torch.tensor(allCitations).T,  # [2, num_edges]\n",
    "    y=y,                    # [num_nodes]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b65ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(768, 256)\n",
    "        self.gcn2 = GCNConv(256, 128)\n",
    "        self.classifier = torch.nn.Linear(128, num_classes)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.relu(self.gcn1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65600cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 5.3493\n",
      "Epoch 1, Loss: 5.2673\n",
      "Epoch 2, Loss: 5.1990\n",
      "Epoch 3, Loss: 5.1323\n",
      "Epoch 4, Loss: 5.0644\n",
      "Epoch 5, Loss: 4.9896\n",
      "Epoch 6, Loss: 4.9067\n",
      "Epoch 7, Loss: 4.8168\n",
      "Epoch 8, Loss: 4.7192\n",
      "Epoch 9, Loss: 4.6135\n",
      "Epoch 10, Loss: 4.5044\n",
      "Epoch 11, Loss: 4.3912\n",
      "Epoch 12, Loss: 4.2680\n",
      "Epoch 13, Loss: 4.1537\n",
      "Epoch 14, Loss: 4.0248\n",
      "Epoch 15, Loss: 3.9033\n",
      "Epoch 16, Loss: 3.7802\n",
      "Epoch 17, Loss: 3.6558\n",
      "Epoch 18, Loss: 3.5314\n",
      "Epoch 19, Loss: 3.4143\n",
      "Epoch 20, Loss: 3.3005\n",
      "Epoch 21, Loss: 3.1897\n",
      "Epoch 22, Loss: 3.0818\n",
      "Epoch 23, Loss: 2.9803\n",
      "Epoch 24, Loss: 2.8826\n",
      "Epoch 25, Loss: 2.7881\n",
      "Epoch 26, Loss: 2.7016\n",
      "Epoch 27, Loss: 2.6131\n",
      "Epoch 28, Loss: 2.5364\n",
      "Epoch 29, Loss: 2.4617\n",
      "Epoch 30, Loss: 2.4013\n",
      "Epoch 31, Loss: 2.3368\n",
      "Epoch 32, Loss: 2.2829\n",
      "Epoch 33, Loss: 2.2210\n",
      "Epoch 34, Loss: 2.1692\n",
      "Epoch 35, Loss: 2.1314\n",
      "Epoch 36, Loss: 2.0780\n",
      "Epoch 37, Loss: 2.0416\n",
      "Epoch 38, Loss: 2.0011\n",
      "Epoch 39, Loss: 1.9699\n",
      "Epoch 40, Loss: 1.9395\n",
      "Epoch 41, Loss: 1.9134\n",
      "Epoch 42, Loss: 1.8781\n",
      "Epoch 43, Loss: 1.8532\n",
      "Epoch 44, Loss: 1.8261\n",
      "Epoch 45, Loss: 1.8057\n",
      "Epoch 46, Loss: 1.7826\n",
      "Epoch 47, Loss: 1.7613\n",
      "Epoch 48, Loss: 1.7453\n",
      "Epoch 49, Loss: 1.7304\n",
      "Epoch 50, Loss: 1.7073\n",
      "Epoch 51, Loss: 1.6888\n",
      "Epoch 52, Loss: 1.6754\n",
      "Epoch 53, Loss: 1.6633\n",
      "Epoch 54, Loss: 1.6490\n",
      "Epoch 55, Loss: 1.6366\n",
      "Epoch 56, Loss: 1.6216\n",
      "Epoch 57, Loss: 1.6103\n",
      "Epoch 58, Loss: 1.5964\n",
      "Epoch 59, Loss: 1.5852\n",
      "Epoch 60, Loss: 1.5777\n",
      "Epoch 61, Loss: 1.5693\n",
      "Epoch 62, Loss: 1.5571\n",
      "Epoch 63, Loss: 1.5471\n",
      "Epoch 64, Loss: 1.5374\n",
      "Epoch 65, Loss: 1.5278\n",
      "Epoch 66, Loss: 1.5202\n",
      "Epoch 67, Loss: 1.5116\n",
      "Epoch 68, Loss: 1.5045\n",
      "Epoch 69, Loss: 1.4963\n",
      "Epoch 70, Loss: 1.4913\n",
      "Epoch 71, Loss: 1.4732\n",
      "Epoch 72, Loss: 1.4711\n",
      "Epoch 73, Loss: 1.4638\n",
      "Epoch 74, Loss: 1.4538\n",
      "Epoch 75, Loss: 1.4494\n",
      "Epoch 76, Loss: 1.4402\n",
      "Epoch 77, Loss: 1.4368\n",
      "Epoch 78, Loss: 1.4357\n",
      "Epoch 79, Loss: 1.4225\n",
      "Epoch 80, Loss: 1.4225\n",
      "Epoch 81, Loss: 1.4093\n",
      "Epoch 82, Loss: 1.4106\n",
      "Epoch 83, Loss: 1.4075\n",
      "Epoch 84, Loss: 1.3986\n",
      "Epoch 85, Loss: 1.3914\n",
      "Epoch 86, Loss: 1.3828\n",
      "Epoch 87, Loss: 1.3828\n",
      "Epoch 88, Loss: 1.3728\n",
      "Epoch 89, Loss: 1.3660\n",
      "Epoch 90, Loss: 1.3661\n",
      "Epoch 91, Loss: 1.3610\n",
      "Epoch 92, Loss: 1.3498\n",
      "Epoch 93, Loss: 1.3494\n",
      "Epoch 94, Loss: 1.3490\n",
      "Epoch 95, Loss: 1.3407\n",
      "Epoch 96, Loss: 1.3417\n",
      "Epoch 97, Loss: 1.3314\n",
      "Epoch 98, Loss: 1.3287\n",
      "Epoch 99, Loss: 1.3257\n"
     ]
    }
   ],
   "source": [
    "model = GNNModel(200).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Assuming `data` is your PyG Data object (with .x, .edge_index, .y, .train_mask)\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data.x, data.edge_index)             # forward pass\n",
    "    loss = torch.nn.functional.cross_entropy(out, data.y)  # compute loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0418ad0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b1816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = model.relu(model.gcn1(data.x, data.edge_index))\n",
    "    newEmbeddings = model.gcn2(x, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da180f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42000, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newEmbeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d81bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = newEmbeddings[0].unsqueeze(0)  # shape: [1, 128]\n",
    "\n",
    "cosine_sim = F.cosine_similarity(query_embedding, newEmbeddings, dim=1)  # shape: [N]\n",
    "\n",
    "topk = torch.topk(cosine_sim, k=5)  # top 5 most similar articles\n",
    "topk_indices = topk.indices\n",
    "topk_scores = topk.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1fbf4535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9317, 0.9231, 0.9077, 0.8981])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([    0, 27424,  4370, 19191, 29419])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(topk_scores)\n",
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89f6c36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "publication_ID                                             17396995\n",
       "Citations         17957262;21818356;24164861;21818356;24164861;2...\n",
       "pubDate                                                  2007 May 1\n",
       "language                                                        eng\n",
       "title             Herpes simplex virus type 2 infection does not...\n",
       "journal                          The Journal of infectious diseases\n",
       "abstract          We sought to compare baseline and longitudinal...\n",
       "keywords          Adult;California;epidemiology;Cohort Studies;H...\n",
       "authors           Edward R Cachay; Simon D W Frost; Douglas D Ri...\n",
       "venue                {'name': 'The Journal of infectious diseases'}\n",
       "doi                                                  10.1086/513568\n",
       "combined_text     Herpes simplex virus type 2 infection does not...\n",
       "embedding         [0.025286998599767685, -0.01651591807603836, 0...\n",
       "cluster                                                           6\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91ef10d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herpes simplex virus type 2 infection does not influence viral dynamics during early HIV 1 infection\n",
      "We sought to compare baseline and longitudinal plasma HIV-1 loads between herpes simplex virus type 2 (HSV-2)-seropositive and -seronegative individuals who are enrolled in a primary HIV-1 infection cohort in San Diego, California.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(df.iloc[idx][\"title\"])\n",
    "print(df.iloc[idx][\"abstract\"])\n",
    "print(df.iloc[idx][\"cluster\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e0b3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herpes simplex virus type 2 acquisition during recent HIV infection does not influence plasma HIV levels\n",
      "We assessed the effect of herpes simplex virus type 2 (HSV-2) acquisition on the plasma HIV RNA and CD4 cell levels among individuals with primary HIV infection using a retrospective cohort analysis. We studied 119 adult, antiretroviral-naive, recently HIV-infected men with a negative HSV-2-specific enzyme immunoassay (EIA) result at enrollment. HSV-2 acquisition was determined by seroconversion on HSV-2 EIA, confirmed by Western blot analysis. Ten men acquired HSV-2 infection a median of 1.3 years after HIV infection (HSV-2 incidence rate of 7.4 per 100 person-years of follow-up). The median time of follow-up after acquiring HSV-2 infection was 303 days. All men except 1 were asymptomatic during HSV-2 acquisition, and only 1 HSV-2 seroconverter, who was asymptomatic, had a transient increase in blood HIV load (0.5 log10 copies/mL over 11 days). The HSV-2 incidence rate was high in our cohort of recently HIV-infected individuals; however, HSV-2 acquisition did not significantly change the plasma HIV dynamics and CD4 cell levels.\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "idx = 4370\n",
    "\n",
    "print(df.iloc[idx][\"title\"])\n",
    "print(df.iloc[idx][\"abstract\"])\n",
    "print(df.iloc[idx][\"cluster\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "157738d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(proj, gcn, temperature=0.1):\n",
    "    proj = torch.nn.functional.normalize(proj, dim=1)\n",
    "    gcn = torch.nn.functional.normalize(gcn, dim=1)\n",
    "    logits = torch.matmul(proj, gcn.T) / temperature\n",
    "    labels = torch.arange(len(proj)).to(proj.device)\n",
    "    return torch.nn.functional.cross_entropy(logits, labels)\n",
    "\n",
    "def mse_alignment_loss(gcn_features, projected_features):\n",
    "    return torch.nn.functional.mse_loss(projected_features, gcn_features)\n",
    "\n",
    "def cosine_alignment_loss(gcn_features, projected_features):\n",
    "    gcn_features = torch.nn.functional.normalize(gcn_features, dim=1)\n",
    "    projected_features = torch.nn.functional.normalize(projected_features, dim=1)\n",
    "    return 1 - (gcn_features * projected_features).sum(dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8059fa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "projector = torch.nn.Sequential(\n",
    "    torch.nn.Linear(768, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(256, 128),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c79a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingDataset = TensorDataset(torch.tensor(embeddings), newEmbeddings)\n",
    "embeddingsLoader = DataLoader(embeddingDataset, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2769b16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06aaabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectorOptim = torch.optim.Adam(projector.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4ae18ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss: 0.0816 | Cosine Sim: 0.9184 | MSE: 4.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.0392 | Cosine Sim: 0.9608 | MSE: 3.7519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Loss: 0.0369 | Cosine Sim: 0.9631 | MSE: 3.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Loss: 0.0355 | Cosine Sim: 0.9645 | MSE: 3.2530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Loss: 0.0345 | Cosine Sim: 0.9655 | MSE: 3.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Loss: 0.0337 | Cosine Sim: 0.9663 | MSE: 2.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Loss: 0.0330 | Cosine Sim: 0.9670 | MSE: 2.5764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Loss: 0.0325 | Cosine Sim: 0.9675 | MSE: 2.3644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Loss: 0.0319 | Cosine Sim: 0.9681 | MSE: 2.1602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Loss: 0.0314 | Cosine Sim: 0.9686 | MSE: 1.9662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Loss: 0.0309 | Cosine Sim: 0.9691 | MSE: 1.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Loss: 0.0304 | Cosine Sim: 0.9696 | MSE: 1.6136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Loss: 0.0300 | Cosine Sim: 0.9700 | MSE: 1.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Loss: 0.0296 | Cosine Sim: 0.9704 | MSE: 1.3059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Loss: 0.0292 | Cosine Sim: 0.9708 | MSE: 1.1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Loss: 0.0288 | Cosine Sim: 0.9712 | MSE: 1.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Loss: 0.0285 | Cosine Sim: 0.9715 | MSE: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Loss: 0.0281 | Cosine Sim: 0.9719 | MSE: 0.8292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Loss: 0.0278 | Cosine Sim: 0.9722 | MSE: 0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Loss: 0.0275 | Cosine Sim: 0.9725 | MSE: 0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Loss: 0.0272 | Cosine Sim: 0.9728 | MSE: 0.5870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Loss: 0.0270 | Cosine Sim: 0.9730 | MSE: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Loss: 0.0267 | Cosine Sim: 0.9733 | MSE: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Loss: 0.0263 | Cosine Sim: 0.9737 | MSE: 0.4394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Loss: 0.0259 | Cosine Sim: 0.9741 | MSE: 0.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m projector\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     26\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(embeddingsLoader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentenceFeat, gnnFeat \u001b[38;5;129;01min\u001b[39;00m loop:\n\u001b[1;32m     28\u001b[0m     sentenceFeat, gnnFeat \u001b[38;5;241m=\u001b[39m sentenceFeat\u001b[38;5;241m.\u001b[39mto(device), gnnFeat\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m     projected_features \u001b[38;5;241m=\u001b[39m projector(sentenceFeat)\n",
      "File \u001b[0;32m~/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    627\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/torch/autograd/profiler.py:631\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/ENTER/envs/HW/lib/python3.10/site-packages/torch/_ops.py:692\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for epoch in tqdm(range(100)):\n",
    "#     for sentenceFeat, gnnFeat in embeddingsLoader:\n",
    "#         sentenceFeat, gnnFeat = sentenceFeat.to(device), gnnFeat.to(device)\n",
    "\n",
    "#         projected_features = projector(sentenceFeat)\n",
    "\n",
    "#         # Choose your loss\n",
    "#         loss = cosine_alignment_loss(gnnFeat, projected_features)\n",
    "\n",
    "#         projectorOptim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch}: {loss.item()}\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_mse = 0.0\n",
    "    epoch_cos_sim = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    projector.train()\n",
    "\n",
    "    loop = tqdm(embeddingsLoader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "    for sentenceFeat, gnnFeat in loop:\n",
    "        sentenceFeat, gnnFeat = sentenceFeat.to(device), gnnFeat.to(device)\n",
    "\n",
    "        projected_features = projector(sentenceFeat)\n",
    "\n",
    "        # Alignment loss (e.g., cosine loss or InfoNCE)\n",
    "        loss = cosine_alignment_loss(gnnFeat, projected_features)\n",
    "\n",
    "        # Metric 1: Cosine similarity\n",
    "        cos_sim = F.cosine_similarity(\n",
    "            F.normalize(projected_features, dim=1),\n",
    "            F.normalize(gnnFeat, dim=1),\n",
    "            dim=1\n",
    "        ).mean().item()\n",
    "\n",
    "        # Metric 2: MSE\n",
    "        mse = F.mse_loss(projected_features, gnnFeat).item()\n",
    "\n",
    "        projectorOptim.zero_grad()\n",
    "        loss.backward()\n",
    "        projectorOptim.step()\n",
    "\n",
    "        # Track stats\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_cos_sim += cos_sim\n",
    "        epoch_mse += mse\n",
    "        total_batches += 1\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), cosine=cos_sim, mse=mse)\n",
    "\n",
    "    # Averages for the epoch\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_cos = epoch_cos_sim / total_batches\n",
    "    avg_mse = epoch_mse / total_batches\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {avg_loss:.4f} | Cosine Sim: {avg_cos:.4f} | MSE: {avg_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e9fe7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = sentTransformer.encode(\"Does HSV-2 infection affect HIV-1 viral load during early infection?\", convert_to_tensor=True).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "218ff794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9475,  0.1267, -0.7355,  2.3193, -1.0245,  5.4224, -0.2830,  5.3337,\n",
       "          1.1157, -1.3054,  0.9092,  3.5090,  0.9092, -1.9904,  5.9561,  1.8709,\n",
       "         -0.8519,  4.1124, -5.8601, -3.2842,  0.8364, -1.7003, -2.5755,  2.5388,\n",
       "          0.1860, -4.8581, -0.0871, -0.0883, -4.0005,  0.4310,  3.0253,  0.5420,\n",
       "          1.1632,  0.6783, -1.9242, -0.5274, -2.2086, -2.8591, -1.2566,  3.7541,\n",
       "          1.6410, -5.4824, -4.4069, -2.0614, -1.3832, -0.8065, -2.8015, -4.5868,\n",
       "          0.4555,  2.3108,  0.7342, -0.4800,  4.1041,  0.5223,  4.1886, -1.6070,\n",
       "         -1.0340, -0.6285, -3.6189, -2.9228, -2.0556,  0.5181,  3.5922, -3.6828,\n",
       "         -2.5354, -0.7375, -2.1428,  1.0271,  2.0640, -0.4872,  0.1799,  2.5157,\n",
       "         -0.1506, -3.8132, -3.9102,  3.4707, -1.8599,  0.8882,  0.1442, -1.5927,\n",
       "         -1.5980,  0.3055,  1.0181, -4.4591, -0.9713, -0.6892, -0.2785, -1.7720,\n",
       "         -0.9992,  1.6119, -1.3113,  2.3926, -1.3130,  1.7119, -0.3259,  1.3891,\n",
       "          0.5427, -1.0244, -3.4228,  1.5987, -1.7591, -1.1926,  1.5818,  3.0205,\n",
       "          0.1231, -1.5201, -1.5223, -1.4930,  0.0401, -0.2948,  0.1961,  1.0238,\n",
       "          1.3073, -0.7139, -1.9914,  3.6083,  2.0861,  1.9938,  0.3898, -4.3516,\n",
       "          1.4113,  1.9613,  0.0272, -0.4417, -0.4647, -0.3594, -3.0977,  1.4238]],\n",
       "       device='cuda:1', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projector(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a220a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = F.cosine_similarity(projector(query), newEmbeddings, dim=1)  # shape: [N]\n",
    "\n",
    "topk = torch.topk(cosine_sim, k=5)  # top 5 most similar articles\n",
    "topk_indices = topk.indices\n",
    "topk_scores = topk.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0fcb789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9356, 0.9348, 0.9341, 0.9319, 0.9285], device='cuda:1',\n",
      "       grad_fn=<TopkBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([32237, 16548,     0,  4370,  3334], device='cuda:1')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(topk_scores)\n",
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c33b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9356, 0.9348, 0.9341, 0.9319, 0.9285], device='cuda:1',\n",
      "       grad_fn=<TopkBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([32237, 16548,     0,  4370,  3334], device='cuda:1')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(topk_scores)\n",
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7680f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV 1 HSV 2 co infected adults in early HIV 1 infection have elevated CD4 T cell counts\n",
      "Introduction HIV-1 is often acquired in the presence of pre-existing co-infections, such as Herpes Simplex Virus 2 (HSV-2). We examined the impact of HSV-2 status at the time of HIV-1 acquisition for its impact on subsequent clinical course, and total CD4+ T cell phenotypes. Methods We assessed the relationship of HSV-1/HSV-2 co-infection status on CD4+ T cell counts and HIV-1 RNA levels over time prior in a cohort of 186 treatment naÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¯ve adults identified during early HIV-1 infection. We assessed the activation and differentiation state of total CD4+ T cells at study entry by HSV-2 status. Results Of 186 recently HIV-1 infected persons, 101 (54 %) were sero-positive for HSV-2. There was no difference in initial CD8+ T cell count, or differences between the groups for age, gender, or race based on HSV-2 status. Persons with HIV-1/HSV-2 co-infection sustained higher CD4+ T cell counts over time (+69 cells/ul greater (SDÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¢ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ=ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¢ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ33.7, pÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¢ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ=ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¢ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ0.04) than those with HIV-1 infection alone ( Figure 1 ), after adjustment for HIV-1 RNA levels (ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¢ÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ57 cells per 1 log 10 higher HIV-1 RNA, p<0.0001). We did not observe a relationship between HSV-2 infection status with plasma HIV-1 RNA levels over time. HSV-2 acquistion after HIV-1 acquisition had no impact on CD4+ count or viral load. We did not detect differences in CD4+ T cell activation or differentiation state by HSV-2+ status. Discussion We observed no effect of HSV-2 status on viral load. However, we did observe that treatment naÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂÃÂ¯ve, recently HIV-1 infected adults co-infected with HSV-2+ at the time of HIV-1 acquisition had higher CD4+ T cell counts over time. If verified in other cohorts, this result poses a striking paradox, and its public health implications are not immediately clear.\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "idx = 32237\n",
    "print(df.iloc[idx][\"title\"])\n",
    "print(df.iloc[idx][\"abstract\"])\n",
    "print(df.iloc[idx][\"cluster\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f25f45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubIdToId[9738515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4272ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17957262: HIV 1 HSV 2 co infected adults in early HIV 1 infection have elevated CD4 T cell counts\n",
      "16973556: Selection on the human immunodeficiency virus type 1 proteome following primary infection\n",
      "17396995: Herpes simplex virus type 2 infection does not influence viral dynamics during early HIV 1 infection\n",
      "18197122: Herpes simplex virus type 2 acquisition during recent HIV infection does not influence plasma HIV levels\n",
      "18936487: HIV rebounds from latently infected cells rather than from continuing low level replication\n"
     ]
    }
   ],
   "source": [
    "for val in topk_indices:\n",
    "    pubID = df.iloc[val.cpu().item()][\"publication_ID\"]\n",
    "    title = df.iloc[val.cpu().item()][\"title\"]\n",
    "    \n",
    "    print(f\"{pubID}: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c069723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_ID</th>\n",
       "      <th>Citations</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>doi</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>9738515</td>\n",
       "      <td>22408488;21943363;20878774;30075569;31996227;3...</td>\n",
       "      <td>1998 Sep</td>\n",
       "      <td>eng</td>\n",
       "      <td>Early changes in biochemical markers of bone t...</td>\n",
       "      <td>Journal of bone and mineral research : the off...</td>\n",
       "      <td>Although the antiresorptive agent alendronate ...</td>\n",
       "      <td>Aged;Alendronate;administration &amp; dosage;thera...</td>\n",
       "      <td>S L Greenspan; R A Parker; L Ferguson; H N Ros...</td>\n",
       "      <td>{'name': 'Journal of bone and mineral research...</td>\n",
       "      <td>10.1359/jbmr.1998.13.9.1431</td>\n",
       "      <td>Early changes in biochemical markers of bone t...</td>\n",
       "      <td>[0.0006918551516719162, -0.038948796689510345,...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     publication_ID                                          Citations  \\\n",
       "888         9738515  22408488;21943363;20878774;30075569;31996227;3...   \n",
       "\n",
       "      pubDate language                                              title  \\\n",
       "888  1998 Sep      eng  Early changes in biochemical markers of bone t...   \n",
       "\n",
       "                                               journal  \\\n",
       "888  Journal of bone and mineral research : the off...   \n",
       "\n",
       "                                              abstract  \\\n",
       "888  Although the antiresorptive agent alendronate ...   \n",
       "\n",
       "                                              keywords  \\\n",
       "888  Aged;Alendronate;administration & dosage;thera...   \n",
       "\n",
       "                                               authors  \\\n",
       "888  S L Greenspan; R A Parker; L Ferguson; H N Ros...   \n",
       "\n",
       "                                                 venue  \\\n",
       "888  {'name': 'Journal of bone and mineral research...   \n",
       "\n",
       "                             doi  \\\n",
       "888  10.1359/jbmr.1998.13.9.1431   \n",
       "\n",
       "                                         combined_text  \\\n",
       "888  Early changes in biochemical markers of bone t...   \n",
       "\n",
       "                                             embedding  cluster  \n",
       "888  [0.0006918551516719162, -0.038948796689510345,...       67  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"publication_ID\"] == 9738515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14025c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Early changes in biochemical markers of bone turnover predict the long term response to alendronate therapy in representative elderly women a randomized clinical trial'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[888][\"title\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
